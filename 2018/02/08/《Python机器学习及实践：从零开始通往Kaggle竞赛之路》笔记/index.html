<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.2" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="coding,Kaggle,Machine learning," />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.2" />






<meta name="description" content="MathJax.Hub.Config({ tex2jax: {inlineMath: [[&apos;$&apos;,&apos;$&apos;], [&apos;\\(&apos;,&apos;\\)&apos;]]} });      第一章 简介篇1.1 机器学习综述所谓具备“学习”能力的程序都是指它能够从不断地从经历和数据中吸取经验教训，从而应对未来的预测任务。这种对未知的预测能力叫做泛化力（Generalization）。">
<meta name="keywords" content="coding,Kaggle,Machine learning">
<meta property="og:type" content="article">
<meta property="og:title" content="《Python机器学习及实践：从零开始通往Kaggle竞赛之路》笔记">
<meta property="og:url" content="http://www.mengfansong.me/2018/02/08/《Python机器学习及实践：从零开始通往Kaggle竞赛之路》笔记/index.html">
<meta property="og:site_name" content="松鹅的博客">
<meta property="og:description" content="MathJax.Hub.Config({ tex2jax: {inlineMath: [[&apos;$&apos;,&apos;$&apos;], [&apos;\\(&apos;,&apos;\\)&apos;]]} });      第一章 简介篇1.1 机器学习综述所谓具备“学习”能力的程序都是指它能够从不断地从经历和数据中吸取经验教训，从而应对未来的预测任务。这种对未知的预测能力叫做泛化力（Generalization）。">
<meta property="og:locale" content="zh-Hans">
<meta property="og:updated_time" content="2018-03-14T11:08:24.539Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="《Python机器学习及实践：从零开始通往Kaggle竞赛之路》笔记">
<meta name="twitter:description" content="MathJax.Hub.Config({ tex2jax: {inlineMath: [[&apos;$&apos;,&apos;$&apos;], [&apos;\\(&apos;,&apos;\\)&apos;]]} });      第一章 简介篇1.1 机器学习综述所谓具备“学习”能力的程序都是指它能够从不断地从经历和数据中吸取经验教训，从而应对未来的预测任务。这种对未知的预测能力叫做泛化力（Generalization）。">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '5.1.2',
    sidebar: {"position":"left","display":"post","offset":12,"offset_float":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://www.mengfansong.me/2018/02/08/《Python机器学习及实践：从零开始通往Kaggle竞赛之路》笔记/"/>





  <title>《Python机器学习及实践：从零开始通往Kaggle竞赛之路》笔记 | 松鹅的博客</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">松鹅的博客</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://www.mengfansong.me/2018/02/08/《Python机器学习及实践：从零开始通往Kaggle竞赛之路》笔记/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="松鹅">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="松鹅的博客">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">《Python机器学习及实践：从零开始通往Kaggle竞赛之路》笔记</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-02-08T22:58:00+08:00">
                2018-02-08
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <script type="text/x-mathjax-config">
MathJax.Hub.Config({
tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
});
</script>
<script type="text/javascript" async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>


<h2 id="第一章-简介篇"><a href="#第一章-简介篇" class="headerlink" title="第一章 简介篇"></a>第一章 简介篇</h2><h3 id="1-1-机器学习综述"><a href="#1-1-机器学习综述" class="headerlink" title="1.1 机器学习综述"></a>1.1 机器学习综述</h3><p>所谓具备“学习”能力的程序都是指它能够从不断地从经历和数据中吸取经验教训，从而应对未来的预测任务。这种对未知的预测能力叫做<strong>泛化力（Generalization）</strong>。<br><a id="more"></a></p>
<h4 id="1-1-1-任务（Task）"><a href="#1-1-1-任务（Task）" class="headerlink" title="1.1.1 任务（Task）"></a>1.1.1 任务（Task）</h4><p>监督学习、无监督学习。</p>
<p>监督学习：分类问题、回归问题。</p>
<p>无监督学习：数据降维(Dimensionality Reduction)、聚类问题(Clustering)</p>
<h4 id="1-1-2-经验（Experience）"><a href="#1-1-2-经验（Experience）" class="headerlink" title="1.1.2 经验（Experience）"></a>1.1.2 经验（Experience）</h4><h4 id="1-1-3-性能（Performence）"><a href="#1-1-3-性能（Performence）" class="headerlink" title="1.1.3 性能（Performence）"></a>1.1.3 性能（Performence）</h4><p>经典的肿瘤分类的栗子。</p>
<h3 id="1-2-Python编程库"><a href="#1-2-Python编程库" class="headerlink" title="1.2 Python编程库"></a>1.2 Python编程库</h3><p>NumPy &amp; SciPy、Matplotlib、Scikit-learn、Pandas、Anaconda</p>
<h3 id="1-3-Python环境配置"><a href="#1-3-Python环境配置" class="headerlink" title="1.3 Python环境配置"></a>1.3 Python环境配置</h3><h3 id="1-4-Python编程基础"><a href="#1-4-Python编程基础" class="headerlink" title="1.4 Python编程基础"></a>1.4 Python编程基础</h3><h4 id="Python数据类型"><a href="#Python数据类型" class="headerlink" title="Python数据类型"></a>Python数据类型</h4><p>数字、布尔值、字符串、元组、列表、字典。</p>
<h2 id="基础篇"><a href="#基础篇" class="headerlink" title="基础篇"></a>基础篇</h2><h3 id="2-1-监督学习经典模型"><a href="#2-1-监督学习经典模型" class="headerlink" title="2.1 监督学习经典模型"></a>2.1 监督学习经典模型</h3><ol>
<li>准备训练数据</li>
<li>抽取所需要的特征，形成特征向量</li>
<li>把特征向量连同对应的标记/目标一并送入学习算法中，训练出一个预测模型。</li>
<li>采用同样的特征抽取方法作用于新测试数据，得到用于测试的特征向量。</li>
<li>使用预测模型对这些待测试的特征向量进行预测并得到结果。</li>
</ol>
<h4 id="2-1-1-分类学习"><a href="#2-1-1-分类学习" class="headerlink" title="2.1.1 分类学习"></a>2.1.1 分类学习</h4><p>最基础的是二分类（Binary Classification）问题，判断是非；除此之外还有多类分类、多标签分类问题。</p>
<h5 id="2-1-1-1-线性分类器"><a href="#2-1-1-1-线性分类器" class="headerlink" title="2.1.1.1 线性分类器"></a>2.1.1.1 线性分类器</h5><ul>
<li><strong>模型介绍</strong>：假设特征与分类结果存在线性关系。<ul>
<li>为了映射到[0,1]区间上，用逻辑斯蒂函数替换原有函数关系。$g(z)=\cfrac1{1+e^{-z}}$</li>
<li>当使用一组m个用于训练的特征向量<strong>X</strong>和其对应的分类目标y，我们希望在这组训练集可以取到极大似然估计的概率L（<strong>$\omega$</strong>,b），或者说，至少要在训练集上如此。</li>
</ul>
</li>
<li><strong>数据描述</strong>：<ul>
<li>缺失值问题广泛存在于现实数据中，是ML任务无法回避的问题。</li>
<li>对数据进行预处理。</li>
</ul>
</li>
<li><strong>编程实现</strong>：</li>
<li><strong>性能测评</strong>：<ul>
<li>准确率（Accuracy）</li>
<li>召回率（Recall）= $\cfrac{(True\ positive)}{(True\ positive) + (False\ negative)}$，正确结果占总发生的数量</li>
<li>精确率（Precision）= $\cfrac{(True\ positive)}{(True\ positive) + (False\ positive)}$，正确结果占总判断对的数量。</li>
<li>F1指标（F1 measure） = $\cfrac2{\cfrac1{Precision}+\cfrac1{Recall}}$，两个指标的调和平均数。调和平均数可以对召回率和准确率更加接近的模型给予更高的分数。</li>
<li>对于本例中，我们更关心<strong>召回率</strong>，就是应该被正确识别的恶性肿瘤的百分比。</li>
</ul>
</li>
<li><strong>特点分析</strong>：<ul>
<li>这里使用的模型包括LogisticRegression和SGDClassifier。</li>
</ul>
</li>
</ul>
<h5 id="2-1-1-2-支持向量机（分类）"><a href="#2-1-1-2-支持向量机（分类）" class="headerlink" title="2.1.1.2 支持向量机（分类）"></a>2.1.1.2 支持向量机（分类）</h5><ul>
<li><strong>模型介绍</strong>：<ul>
<li>由于分类模型要作用在未知分布的测试数据上，因此我们更关注<strong>如何最大限度的为位置分布的数据提供足够的待预测空间</strong>。</li>
<li>支持向量机分类器（Support Vector Classifier），根据训练样本的分布，搜索所有可能的线性分类器中的最佳的那个。</li>
<li>决定直线位置的是其中<strong>两个空间间隔最小的两个不同类别的数据点</strong>，把这种可以用来真正帮助决策最优线性分类模型的数据点叫做“支持向量机”。</li>
</ul>
</li>
<li><strong>数据描述</strong>：<ul>
<li>手写数字分类</li>
<li>使用像素矩阵的时候，习惯将2D的图片像素矩阵逐行首尾拼接为1D的像素特征向量。（但是这样会丢失一些结构化的数据）</li>
</ul>
</li>
<li><strong>编程实践</strong>：</li>
<li><strong>性能测评</strong>：<ul>
<li>多类别性能指标的评估：把其他的类别看作阴性样本，便可以创造出10个二分类任务。</li>
</ul>
</li>
<li><strong>特点分析</strong>：<ul>
<li>可以在海量甚至高维度的数据中，筛选对预测任务最为有效的少数训练样本。节省内存，提高模型的预测性能；但要付出更高的计算代价。</li>
</ul>
</li>
</ul>
<h5 id="2-1-1-3-朴素贝叶斯（Naive-Bayes）"><a href="#2-1-1-3-朴素贝叶斯（Naive-Bayes）" class="headerlink" title="2.1.1.3 朴素贝叶斯（Naive Bayes）"></a>2.1.1.3 朴素贝叶斯（Naive Bayes）</h5><ul>
<li><p><strong>模型介绍</strong>：</p>
<ul>
<li>构造的基础是<strong>贝叶斯理论</strong>。</li>
<li>各维度上特征被分类的条件概率之间是独立的。</li>
<li>$P(y = c_i |x)$为特征向量<strong>x</strong>属于类别$c_i$的概率。</li>
<li>$$P(y | x) = \cfrac{P(x|y)P(y)}{P(x)}$$</li>
<li>寻找y∈{$c_1$,$c_2$,…,$c_k$}中P(y|<strong>x</strong>)最大的，考虑到P(x)对于同一个样本都是相同的，因此可以忽略不计。</li>
<li>如果没有特殊假设，需要对$k*2^n$个可能的参数进行估计；但是由于特征类别条件独立假设，只需要估计2kn个参数。</li>
<li>为了估计每个参数的概率，采用$P(x_n=1|y=c_k) = \cfrac{P(x_n=1,y=c_k)}{P(y=c_k)} = \cfrac{(x_n=1,y=c_k)}{(y=c_k)}$公式，把频率近似于概率计算。</li>
</ul>
</li>
<li><p><strong>数据描述</strong>：</p>
<ul>
<li><p>朴素贝叶斯模型有着广泛的实际应用环境，特别是在文本分类的任务中。</p>
</li>
<li><p>使用经典的20类新闻文本作为实验数据。</p>
<ul>
<li><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> fetch_20newsgroups</div><div class="line"><span class="comment">#从互联网下载数据过来</span></div><div class="line">news = fetch_20newsgroups(subset = <span class="string">'all'</span>)</div></pre></td></tr></table></figure>
</li>
</ul>
</li>
</ul>
</li>
<li><p><strong>性能测评</strong>：</p>
</li>
<li><p><strong>特点分析</strong>：</p>
<ul>
<li>广泛应用于互联网文本分类任务。</li>
<li>由于特征条件独立假设，使得估计参数规模大幅度减小</li>
<li>但无法将各个特征之间的联系李考量在内，使得该模型在其他数据特征关联性强的分类任务上性能不佳。</li>
</ul>
</li>
</ul>
<h5 id="2-1-1-4-K近邻（分类）"><a href="#2-1-1-4-K近邻（分类）" class="headerlink" title="2.1.1.4 K近邻（分类）"></a>2.1.1.4 K近邻（分类）</h5><ul>
<li><strong>模型介绍</strong>：<ul>
<li>“近朱者赤，近墨者黑”</li>
<li>最通俗的解释就是：寻找特征空间距离最近的K个已标记样本作为参考。</li>
<li>K值的不同，会产生不同的分类器。</li>
</ul>
</li>
<li><strong>数据描述</strong>：<ul>
<li>利用K近邻算法对生物物种进行分类，使用“鸢尾（Iris）”数据集。</li>
<li>在分割数据样本的时候，一定要<strong>随机</strong>。</li>
</ul>
</li>
<li><strong>特点分析</strong>：<ul>
<li>K近邻算法没有参数训练的过程，属于<strong>无参数模型</strong></li>
<li>$O(n^2)$的复杂度</li>
</ul>
</li>
</ul>
<h5 id="2-1-1-5-决策树"><a href="#2-1-1-5-决策树" class="headerlink" title="2.1.1.5 决策树"></a>2.1.1.5 决策树</h5><ul>
<li><p><strong>模型介绍</strong>:</p>
<ul>
<li>决策树描述非线性关系。</li>
<li><strong>决策树节点（node）</strong>代表数据特征；每个节点下的分支对应特征值的分类；<strong>决策树的所有叶子节点（leaf）</strong>显示模型的决策结果。</li>
<li>不同特征组合搭建多层决策树的情况，就需要考虑特征节点的选取顺序。常用的度量包括<strong>信息熵（Information Gain）</strong>和<strong>基尼不纯性（Gini Imprity）</strong></li>
</ul>
</li>
<li><p><strong>数据描述</strong>：</p>
<ul>
<li><p>利用泰坦尼克号的数据，预测遇难与生还</p>
</li>
<li><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</div><div class="line"></div><div class="line">titanic = pd.read_csv(<span class="string">'http://biostat.mc.vanderbilt.edu/wiki/pub/Main/DataSets/titanic.txt'</span>)</div><div class="line"></div><div class="line">titanic.head()</div><div class="line"></div><div class="line"> x = titanic[[<span class="string">'pclass'</span>,<span class="string">'age'</span>,<span class="string">'sex'</span>]]</div><div class="line"></div><div class="line">In [<span class="number">11</span>]: y = titanic[<span class="string">'survived'</span>]</div><div class="line"></div><div class="line">In [<span class="number">12</span>]: x.info()</div><div class="line">&lt;<span class="class"><span class="keyword">class</span> '<span class="title">pandas</span>.<span class="title">core</span>.<span class="title">frame</span>.<span class="title">DataFrame</span>'&gt;</span></div><div class="line"><span class="class"><span class="title">RangeIndex</span>:</span> <span class="number">1313</span> entries, <span class="number">0</span> to <span class="number">1312</span></div><div class="line">Data columns (total <span class="number">3</span> columns):</div><div class="line">pclass    <span class="number">1313</span> non-null object</div><div class="line">age       <span class="number">633</span> non-null float64</div><div class="line">sex       <span class="number">1313</span> non-null object</div><div class="line">dtypes: float64(<span class="number">1</span>), object(<span class="number">2</span>)</div><div class="line">memory usage: <span class="number">30.9</span>+ KB</div><div class="line"><span class="comment">#对空缺的数据进行补充。</span></div><div class="line">In [<span class="number">13</span>]: x[<span class="string">'age'</span>].fillna(x[<span class="string">'age'</span>].mean(),inplace=<span class="keyword">True</span>)</div></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p><strong>特点分析</strong>：</p>
<ul>
<li>决策树在<strong>模型描述</strong>上有巨大的优势。</li>
<li>决策树的推断逻辑非常直观，具有清晰的可解释性，也方便了模型的可视化。</li>
</ul>
</li>
</ul>
<h5 id="2-1-1-6-集成模型（分类）"><a href="#2-1-1-6-集成模型（分类）" class="headerlink" title="2.1.1.6 集成模型（分类）"></a>2.1.1.6 集成模型（分类）</h5><ul>
<li><strong>模型介绍</strong>：<ul>
<li>综合考量多个分类器的预测结果，从而做出决策。</li>
<li>一种是利用相同的训练数据同时搭建多个独立的分类模型，通过投票的方式，少数服从多数的原则做出最终的分类决策。<ul>
<li><strong>随机森林分类器（Random Forest Classifier）</strong>，在相同训练数据上同时搭建多棵决策树。每一颗决策树随机选取特征。</li>
</ul>
</li>
<li>另一种是按照一定次序搭建多个分类模型。这些模型之间彼此存在依赖关系。每一个后续模型的加入都需要对集成模型的综合性能有所贡献</li>
</ul>
</li>
</ul>
<ul>
<li><strong>性能测评</strong>：<ul>
<li>一般而言，工业界经常使用随机森林分类模型作为基线模型（Baseline System）。</li>
</ul>
</li>
<li><strong>特点分析</strong>：<ul>
<li>集成模型是实战中最常用的，可以整合多种模型，或者多次就一种模型进行建模。耗费时间更多，但是往往具有更高的性能和更好的稳定性。</li>
</ul>
</li>
</ul>
<h4 id="2-1-2-回归预测"><a href="#2-1-2-回归预测" class="headerlink" title="2.1.2 回归预测"></a>2.1.2 回归预测</h4><h5 id="2-1-2-1-线性回归器"><a href="#2-1-2-1-线性回归器" class="headerlink" title="2.1.2.1 线性回归器"></a>2.1.2.1 线性回归器</h5><ul>
<li><strong>模型介绍</strong>：<ul>
<li>希望线性回归模型的最小二乘预测的损失。</li>
</ul>
</li>
<li><strong>性能测评</strong>：<ul>
<li>最为直观的：<strong>平均绝对误差（Mean Absolute Error, MAE）</strong>、<strong>均方误差（Mean Squared Error, MSE）</strong>。</li>
<li><strong>R</strong>-squared评价<ul>
<li>$SS<em>{res} = \sum\limits</em>{i = 1}^m(y^i-f(\boldsymbol x^i))^2$</li>
<li>$R^2 = 1-\cfrac{SS<em>{res}}{SS</em>{tot}}$，$SS<em>{tot}$代表测试数据真实值的方法；$SS</em>{res}$代表回归值与真实值之间的平方差异（回归差异）。</li>
</ul>
</li>
</ul>
</li>
<li><strong>特点分析</strong>：<ul>
<li>简单易用，常被用来作为大多数科学试验的基线系统。</li>
</ul>
</li>
</ul>
<h5 id="2-1-2-2-支持向量机（回归）"><a href="#2-1-2-2-支持向量机（回归）" class="headerlink" title="2.1.2.2 支持向量机（回归）"></a>2.1.2.2 支持向量机（回归）</h5><ul>
<li>线性核函数</li>
<li>多项式核函数</li>
<li>径向基核函数</li>
</ul>
<h5 id="2-1-2-3-K近邻（回归）"><a href="#2-1-2-3-K近邻（回归）" class="headerlink" title="2.1.2.3 K近邻（回归）"></a>2.1.2.3 K近邻（回归）</h5><ul>
<li><strong>预测方式</strong>：<ul>
<li>平均回归</li>
<li>根据距离加权回归</li>
</ul>
</li>
</ul>
<h5 id="2-1-2-4-回归树"><a href="#2-1-2-4-回归树" class="headerlink" title="2.1.2.4 回归树"></a>2.1.2.4 回归树</h5><ul>
<li><strong>模型介绍</strong>：<ul>
<li>回归树节点的数据类型不是离散的，是连续型</li>
</ul>
</li>
<li><strong>特点分析</strong>：<ul>
<li>优点：<ul>
<li>树模型可以解决非线性特征的问题。</li>
<li>树模型不要求<strong>特征标准化</strong>和<strong>统一量化</strong>，即数值型和类别型特征都可以直接被应用在树模型的构建和预测中。</li>
<li>可以直观地输出决策结果。</li>
</ul>
</li>
<li>缺点：<ul>
<li>容易因为模型搭建过于复杂而失去对数据预测的精度（泛化力）。</li>
<li>会因为数据细微的改变而发生较大的结构变化，预测稳定性较差。</li>
<li>构建最佳的树模型是NP-hard问题，所以用贪婪算法智能找到一些次优解。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h5 id="2-1-2-5-集成模型（回归）"><a href="#2-1-2-5-集成模型（回归）" class="headerlink" title="2.1.2.5 集成模型（回归）"></a>2.1.2.5 集成模型（回归）</h5><ul>
<li><strong>模型介绍</strong>：<ul>
<li><strong>极端随机森林（Extremely Randomized Trees）</strong>：每当构建一棵树的分裂节点的时候，不会任意地选取特征；而是先随机收集一部分特征，然后利用信息熵和基尼不纯性等指标挑选最佳的节点特征。</li>
</ul>
</li>
</ul>
<h3 id="2-2-无监督学习经典模型"><a href="#2-2-无监督学习经典模型" class="headerlink" title="2.2 无监督学习经典模型"></a>2.2 无监督学习经典模型</h3><p>无监督学习不需要对数据进行标记，可以帮助我们发现数据的“群落”，同时也可以寻找“离群”的样本；对于特征维度非常高的数据样本，可以对数据进行降维。</p>
<h4 id="数据聚类"><a href="#数据聚类" class="headerlink" title="数据聚类"></a>数据聚类</h4><h5 id="2-2-1-1-K均值算法"><a href="#2-2-1-1-K均值算法" class="headerlink" title="2.2.1.1 K均值算法"></a>2.2.1.1 K均值算法</h5><ul>
<li><p><strong>模型介绍</strong>：</p>
<ul>
<li>最经典、相对容易理解的模型。</li>
<li>步骤：<ol>
<li>随机布设K个特征空间内的点作为初始的聚类中心</li>
<li>对于每个数据的特征向量，从K个聚类中心中寻找距离最近的一个，并且把这个数据标记为从属于这个聚类中心</li>
<li>在所有数据都被标记过聚类中心后，根据数据新分配的类簇，重新对中心进行计算。</li>
<li>如果一轮结束，所有的数据点从属的聚类中心与上一次分配的没有变化，则可以停止。否则循环。</li>
</ol>
</li>
</ul>
</li>
<li><p><strong>数据描述</strong>：</p>
</li>
<li><p><strong>性能测评</strong>：</p>
<ul>
<li><p><strong>Adjusted Rand Index（ARI）</strong>，评估的数据本身带有正确的类别信息。</p>
</li>
<li><p><strong>轮廓系数（Silhouette Coefficient）</strong>，兼顾聚类的凝聚度（Cohesion）和分离度（Separation），取值范围为[-1,1]。</p>
<ol>
<li>对于已聚类数据中的第i个样本$x^i$，计算其与同一个类簇内的所有其他样本距离的平均值，记作$a^i$，用来量化凝聚度。</li>
<li>选取$x^i$外的一个簇b，计算其与b中所有样本的平均距离，遍历所有其他簇，找到最近的这个平均距离，记作$b^i$，用于量化分离度。</li>
<li>对于样本$x^i$，轮廓系数 $sc^i = \cfrac{b^i - a^i}{max(b^i, a^i)}$</li>
<li>对所有样本X求出平均值，即为当前聚类结果的整体轮廓系数。</li>
</ol>
<p>如果$sc^i$小于0，说明簇内元素的平均距离大于最近的其他簇，聚类效果不好；如果$a^i$趋于0，或者$b^i$足够大，那么$sc^i$趋于1，说明聚类效果比较好。</p>
</li>
</ul>
</li>
<li><p><strong>特点分析</strong>：</p>
<ul>
<li>直观易懂非常实用</li>
<li>两大缺陷：<ol>
<li>容易收敛到局部最优解</li>
<li>需要预先设定簇的数量。</li>
</ol>
</li>
<li>“肘部”观察法粗略地预估相对合理的类簇个数。利用拐点的特性判断K值。</li>
</ul>
</li>
</ul>
<h4 id="2-2-2-特征降维"><a href="#2-2-2-特征降维" class="headerlink" title="2.2.2 特征降维"></a>2.2.2 特征降维</h4><p>特征维度非常高，无法借助领域知识人工构建有效特征；</p>
<p>无法用肉眼观察超过三个维度的特征。</p>
<h5 id="2-2-2-1-主成分分析（Principal-Component-Analysis）"><a href="#2-2-2-1-主成分分析（Principal-Component-Analysis）" class="headerlink" title="2.2.2.1 主成分分析（Principal Component Analysis）"></a>2.2.2.1 主成分分析（Principal Component Analysis）</h5><ul>
<li><strong>模型介绍</strong>：<ul>
<li>首先把原来的特征空间做映射，使的新的映射后特征空间数据彼此正交，这样可以通过主成分分析保留下具备区分性的低维数据特征。</li>
<li>会损失一定的预测准确性，但是使用PCA可以压缩并降低维度。</li>
</ul>
</li>
<li><strong>特点分析</strong>：<ul>
<li>降维/压缩问题是选取数据具有代表性的特征，在保持数据多样性的基础上，规避掉大量的特征荣冗余和噪声。</li>
</ul>
</li>
</ul>
<h2 id="进阶篇"><a href="#进阶篇" class="headerlink" title="进阶篇"></a>进阶篇</h2><h3 id="3-1-模型实用技巧"><a href="#3-1-模型实用技巧" class="headerlink" title="3.1 模型实用技巧"></a>3.1 模型实用技巧</h3><p>并不能保证：</p>
<ol>
<li>所有用于训练的数据特征都是最好的</li>
<li>学习得到的参数一定是最优的</li>
<li>默认配置下的模型总是最佳的</li>
</ol>
<h4 id="3-1-1-特征提升"><a href="#3-1-1-特征提升" class="headerlink" title="3.1.1 特征提升"></a>3.1.1 特征提升</h4><p>特征抽取：逐条将原始数据转化为特征向量的形式，这个过程同时涉及对数据特征的量化表示；而特征筛选更进一步，在高维度、已量化的特征向量中选择对制定任务更有效的特征组合，提升性能。</p>
<h5 id="3-1-1-1-特征抽取"><a href="#3-1-1-1-特征抽取" class="headerlink" title="3.1.1.1 特征抽取"></a>3.1.1.1 特征抽取</h5><ul>
<li>对于文字等类型的数据，不能直接处理，需要抽出成特征向量。<ul>
<li>结构化的数据，可以改成用0/1表示。</li>
<li>词袋法（Bag of Words）</li>
<li>词表（Vocabulary）</li>
</ul>
</li>
<li><strong>特征数值</strong>的计算<ul>
<li>CountVectorizer<ul>
<li>只考虑每种词汇在该条训练文本中出现的频率</li>
</ul>
</li>
<li>TfidfVectorizer<ul>
<li>还包括这个词汇的文本条数的倒数（比如the可能就没那么重要，这种词成为停用词Stop Words</li>
<li>停用词往往就被压制掉了</li>
</ul>
</li>
</ul>
</li>
</ul>
<h5 id="3-1-1-2-特征筛选"><a href="#3-1-1-2-特征筛选" class="headerlink" title="3.1.1.2 特征筛选"></a>3.1.1.2 特征筛选</h5><p>特征筛选与PCA对特征的重建略有不同：对于PCA而言，<strong>无法解释重建后的特征</strong>；但特征筛选<strong>不存在对特征值的修改</strong>，更加侧重于寻找那些对模型的性能提升较大的少量特征。</p>
<h4 id="3-1-2-模型正则化"><a href="#3-1-2-模型正则化" class="headerlink" title="3.1.2 模型正则化"></a>3.1.2 模型正则化</h4><p>泛化力（Generalization）</p>
<h5 id="3-1-2-1-欠拟合与过拟合"><a href="#3-1-2-1-欠拟合与过拟合" class="headerlink" title="3.1.2.1 欠拟合与过拟合"></a>3.1.2.1 欠拟合与过拟合</h5><h5 id="3-1-2-2-L-1-范数正则化"><a href="#3-1-2-2-L-1-范数正则化" class="headerlink" title="3.1.2.2 $L_1$范数正则化"></a>3.1.2.2 $L_1$范数正则化</h5><p>正则化（Regularization）的目的在于提高模型在未知测试数据上的泛化力，避免过拟合。</p>
<p>在原优化目标的基础上，增加了参数向量的$L_1$范数，增加对参数的惩罚（Penalty）项。这样会让参数向量中的许多元素趋近于0，使大部分特征是去优化目标的贡献。被称为<code>Lasso</code>。</p>
<h5 id="3-1-2-3-L-2-范数正则化"><a href="#3-1-2-3-L-2-范数正则化" class="headerlink" title="3.1.2.3 $L_2$范数正则化"></a>3.1.2.3 $L_2$范数正则化</h5><p>会让参数向量中的大部分元素都变得很小，压制了参数之间的差异性。称为<code>Ridge</code>。</p>
<h4 id="3-1-3-模型检验"><a href="#3-1-3-模型检验" class="headerlink" title="3.1.3 模型检验"></a>3.1.3 模型检验</h4><h5 id="3-1-3-1-留一验证"><a href="#3-1-3-1-留一验证" class="headerlink" title="3.1.3.1 留一验证"></a>3.1.3.1 留一验证</h5><h5 id="3-1-3-2-交叉验证"><a href="#3-1-3-2-交叉验证" class="headerlink" title="3.1.3.2 交叉验证"></a>3.1.3.2 交叉验证</h5><p>交叉验证（K-fold cross-validation）可以理解为从事了多次留一验证的过程。</p>
<h4 id="3-1-4-超参数搜索"><a href="#3-1-4-超参数搜索" class="headerlink" title="3.1.4 超参数搜索"></a>3.1.4 超参数搜索</h4><p>超参数的选择是无数的，我们也可以通过启发式的搜索方式对超参数组合进行调优。</p>
<h5 id="3-1-4-1-网格搜索（GridSearch）"><a href="#3-1-4-1-网格搜索（GridSearch）" class="headerlink" title="3.1.4.1 网格搜索（GridSearch）"></a>3.1.4.1 网格搜索（GridSearch）</h5><h5 id="3-1-4-2-并行搜索"><a href="#3-1-4-2-并行搜索" class="headerlink" title="3.1.4.2 并行搜索"></a>3.1.4.2 并行搜索</h5><p>多线程并行搜索技术进行调优。</p>
<h3 id="3-2-流行库-模型实践"><a href="#3-2-流行库-模型实践" class="headerlink" title="3.2 流行库/模型实践"></a>3.2 流行库/模型实践</h3><h4 id="3-2-1-自然语言处理包（NLTK）"><a href="#3-2-1-自然语言处理包（NLTK）" class="headerlink" title="3.2.1 自然语言处理包（NLTK）"></a>3.2.1 自然语言处理包（NLTK）</h4><h4 id="3-2-2-词向量（Word2Vec）技术"><a href="#3-2-2-词向量（Word2Vec）技术" class="headerlink" title="3.2.2 词向量（Word2Vec）技术"></a>3.2.2 词向量（Word2Vec）技术</h4><h4 id="3-2-3-XGBoost模型"><a href="#3-2-3-XGBoost模型" class="headerlink" title="3.2.3 XGBoost模型"></a>3.2.3 XGBoost模型</h4><p>利用多线程模型进行计算</p>
<h4 id="3-2-4-Tensorflow"><a href="#3-2-4-Tensorflow" class="headerlink" title="3.2.4 Tensorflow"></a>3.2.4 Tensorflow</h4><p>一个编程框架，另一个小东西叫skflow</p>
<ul>
<li>深度神经网络DNN：<ul>
<li>小心过拟合的问题</li>
</ul>
</li>
</ul>
<h2 id="实战篇"><a href="#实战篇" class="headerlink" title="实战篇"></a>实战篇</h2><h3 id="4-1-Kaggle平台"><a href="#4-1-Kaggle平台" class="headerlink" title="4.1 Kaggle平台"></a>4.1 Kaggle平台</h3><p>提供数据分析及预测模型的竞赛平台。</p>
<ul>
<li>kaggle提供可以线上编程的云平台，但资源有限，只有512MB的硬盘和20分钟的运算时间。</li>
<li>Kaggle会采用历史最好成绩做出最终的排名。</li>
</ul>
<h4 id="4-2-Titanic罹难乘客预测"><a href="#4-2-Titanic罹难乘客预测" class="headerlink" title="4.2 Titanic罹难乘客预测"></a>4.2 Titanic罹难乘客预测</h4><h4 id="4-3-IMDB影评得分估计"><a href="#4-3-IMDB影评得分估计" class="headerlink" title="4.3 IMDB影评得分估计"></a>4.3 IMDB影评得分估计</h4><p>标有情感倾向的训练文件来进行预测。</p>
<p>倾向于自然语言处理（NLP）的内容。</p>
<h4 id="4-4-MNIST手写体数字图片识别"><a href="#4-4-MNIST手写体数字图片识别" class="headerlink" title="4.4 MNIST手写体数字图片识别"></a>4.4 MNIST手写体数字图片识别</h4>
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/coding/" rel="tag"># coding</a>
          
            <a href="/tags/Kaggle/" rel="tag"># Kaggle</a>
          
            <a href="/tags/Machine-learning/" rel="tag"># Machine learning</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2018/02/03/set容器自定义排序/" rel="next" title="set容器自定义排序">
                <i class="fa fa-chevron-left"></i> set容器自定义排序
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2018/03/07/delete-code-comments-by-regexp/" rel="prev" title="利用正则表达式删除代码中的注释">
                利用正则表达式删除代码中的注释 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          
            <p class="site-author-name" itemprop="name">松鹅</p>
            <p class="site-description motion-element" itemprop="description"></p>
        </div>

        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
            
              <a href="/archives/">
            
                <span class="site-state-item-count">11</span>
                <span class="site-state-item-name">日志</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-categories">
              
                <span class="site-state-item-count">2</span>
                <span class="site-state-item-name">分类</span>
              
            </div>
          

          
            
            
            <div class="site-state-item site-state-tags">
              
                <span class="site-state-item-count">8</span>
                <span class="site-state-item-name">标签</span>
              
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="https://github.com/dreamgod2016" target="_blank" title="GitHub">
                  
                    <i class="fa fa-fw fa-github"></i>GitHub</a>
              </span>
            
              <span class="links-of-author-item">
                <a href="mailto:dreamgod007@gmail.com" target="_blank" title="E-Mail">
                  
                    <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
              </span>
            
          
        </div>

        
        

        
        

        


      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#第一章-简介篇"><span class="nav-number">1.</span> <span class="nav-text">第一章 简介篇</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-1-机器学习综述"><span class="nav-number">1.1.</span> <span class="nav-text">1.1 机器学习综述</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1-1-1-任务（Task）"><span class="nav-number">1.1.1.</span> <span class="nav-text">1.1.1 任务（Task）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#1-1-2-经验（Experience）"><span class="nav-number">1.1.2.</span> <span class="nav-text">1.1.2 经验（Experience）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#1-1-3-性能（Performence）"><span class="nav-number">1.1.3.</span> <span class="nav-text">1.1.3 性能（Performence）</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-2-Python编程库"><span class="nav-number">1.2.</span> <span class="nav-text">1.2 Python编程库</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-3-Python环境配置"><span class="nav-number">1.3.</span> <span class="nav-text">1.3 Python环境配置</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-4-Python编程基础"><span class="nav-number">1.4.</span> <span class="nav-text">1.4 Python编程基础</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Python数据类型"><span class="nav-number">1.4.1.</span> <span class="nav-text">Python数据类型</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#基础篇"><span class="nav-number">2.</span> <span class="nav-text">基础篇</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#2-1-监督学习经典模型"><span class="nav-number">2.1.</span> <span class="nav-text">2.1 监督学习经典模型</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#2-1-1-分类学习"><span class="nav-number">2.1.1.</span> <span class="nav-text">2.1.1 分类学习</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#2-1-1-1-线性分类器"><span class="nav-number">2.1.1.1.</span> <span class="nav-text">2.1.1.1 线性分类器</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2-1-1-2-支持向量机（分类）"><span class="nav-number">2.1.1.2.</span> <span class="nav-text">2.1.1.2 支持向量机（分类）</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2-1-1-3-朴素贝叶斯（Naive-Bayes）"><span class="nav-number">2.1.1.3.</span> <span class="nav-text">2.1.1.3 朴素贝叶斯（Naive Bayes）</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2-1-1-4-K近邻（分类）"><span class="nav-number">2.1.1.4.</span> <span class="nav-text">2.1.1.4 K近邻（分类）</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2-1-1-5-决策树"><span class="nav-number">2.1.1.5.</span> <span class="nav-text">2.1.1.5 决策树</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2-1-1-6-集成模型（分类）"><span class="nav-number">2.1.1.6.</span> <span class="nav-text">2.1.1.6 集成模型（分类）</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-1-2-回归预测"><span class="nav-number">2.1.2.</span> <span class="nav-text">2.1.2 回归预测</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#2-1-2-1-线性回归器"><span class="nav-number">2.1.2.1.</span> <span class="nav-text">2.1.2.1 线性回归器</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2-1-2-2-支持向量机（回归）"><span class="nav-number">2.1.2.2.</span> <span class="nav-text">2.1.2.2 支持向量机（回归）</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2-1-2-3-K近邻（回归）"><span class="nav-number">2.1.2.3.</span> <span class="nav-text">2.1.2.3 K近邻（回归）</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2-1-2-4-回归树"><span class="nav-number">2.1.2.4.</span> <span class="nav-text">2.1.2.4 回归树</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2-1-2-5-集成模型（回归）"><span class="nav-number">2.1.2.5.</span> <span class="nav-text">2.1.2.5 集成模型（回归）</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-2-无监督学习经典模型"><span class="nav-number">2.2.</span> <span class="nav-text">2.2 无监督学习经典模型</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#数据聚类"><span class="nav-number">2.2.1.</span> <span class="nav-text">数据聚类</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#2-2-1-1-K均值算法"><span class="nav-number">2.2.1.1.</span> <span class="nav-text">2.2.1.1 K均值算法</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-2-2-特征降维"><span class="nav-number">2.2.2.</span> <span class="nav-text">2.2.2 特征降维</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#2-2-2-1-主成分分析（Principal-Component-Analysis）"><span class="nav-number">2.2.2.1.</span> <span class="nav-text">2.2.2.1 主成分分析（Principal Component Analysis）</span></a></li></ol></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#进阶篇"><span class="nav-number">3.</span> <span class="nav-text">进阶篇</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#3-1-模型实用技巧"><span class="nav-number">3.1.</span> <span class="nav-text">3.1 模型实用技巧</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#3-1-1-特征提升"><span class="nav-number">3.1.1.</span> <span class="nav-text">3.1.1 特征提升</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#3-1-1-1-特征抽取"><span class="nav-number">3.1.1.1.</span> <span class="nav-text">3.1.1.1 特征抽取</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#3-1-1-2-特征筛选"><span class="nav-number">3.1.1.2.</span> <span class="nav-text">3.1.1.2 特征筛选</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-1-2-模型正则化"><span class="nav-number">3.1.2.</span> <span class="nav-text">3.1.2 模型正则化</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#3-1-2-1-欠拟合与过拟合"><span class="nav-number">3.1.2.1.</span> <span class="nav-text">3.1.2.1 欠拟合与过拟合</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#3-1-2-2-L-1-范数正则化"><span class="nav-number">3.1.2.2.</span> <span class="nav-text">3.1.2.2 $L_1$范数正则化</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#3-1-2-3-L-2-范数正则化"><span class="nav-number">3.1.2.3.</span> <span class="nav-text">3.1.2.3 $L_2$范数正则化</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-1-3-模型检验"><span class="nav-number">3.1.3.</span> <span class="nav-text">3.1.3 模型检验</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#3-1-3-1-留一验证"><span class="nav-number">3.1.3.1.</span> <span class="nav-text">3.1.3.1 留一验证</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#3-1-3-2-交叉验证"><span class="nav-number">3.1.3.2.</span> <span class="nav-text">3.1.3.2 交叉验证</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-1-4-超参数搜索"><span class="nav-number">3.1.4.</span> <span class="nav-text">3.1.4 超参数搜索</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#3-1-4-1-网格搜索（GridSearch）"><span class="nav-number">3.1.4.1.</span> <span class="nav-text">3.1.4.1 网格搜索（GridSearch）</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#3-1-4-2-并行搜索"><span class="nav-number">3.1.4.2.</span> <span class="nav-text">3.1.4.2 并行搜索</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-2-流行库-模型实践"><span class="nav-number">3.2.</span> <span class="nav-text">3.2 流行库/模型实践</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#3-2-1-自然语言处理包（NLTK）"><span class="nav-number">3.2.1.</span> <span class="nav-text">3.2.1 自然语言处理包（NLTK）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-2-2-词向量（Word2Vec）技术"><span class="nav-number">3.2.2.</span> <span class="nav-text">3.2.2 词向量（Word2Vec）技术</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-2-3-XGBoost模型"><span class="nav-number">3.2.3.</span> <span class="nav-text">3.2.3 XGBoost模型</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-2-4-Tensorflow"><span class="nav-number">3.2.4.</span> <span class="nav-text">3.2.4 Tensorflow</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#实战篇"><span class="nav-number">4.</span> <span class="nav-text">实战篇</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#4-1-Kaggle平台"><span class="nav-number">4.1.</span> <span class="nav-text">4.1 Kaggle平台</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#4-2-Titanic罹难乘客预测"><span class="nav-number">4.1.1.</span> <span class="nav-text">4.2 Titanic罹难乘客预测</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-3-IMDB影评得分估计"><span class="nav-number">4.1.2.</span> <span class="nav-text">4.3 IMDB影评得分估计</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-4-MNIST手写体数字图片识别"><span class="nav-number">4.1.3.</span> <span class="nav-text">4.4 MNIST手写体数字图片识别</span></a></li></ol></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">松鹅</span>

  
</div>
<div style="display:none;">
<script type="text/javascript">var cnzz_protocol = (("https:" == document.location.protocol) ? " https://" : " http://");document.write(unescape("%3Cspan id='cnzz_stat_icon_1264920242'%3E%3C/span%3E%3Cscript src='" + cnzz_protocol + "s13.cnzz.com/z_stat.php%3Fid%3D1264920242' type='text/javascript'%3E%3C/script%3E"));</script>
</div>

<!--

  <div class="powered-by">由 <a class="theme-link" href="https://hexo.io">Hexo</a> 强力驱动</div>


-->
        







  <div style="display: none;">
    <script src="//s95.cnzz.com/z_stat.php?id=1264920242&web_id=1264920242" language="JavaScript"></script>
  </div>



        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.2"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.2"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.2"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.2"></script>



  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.2"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.2"></script>


  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.2"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.2"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.2"></script>



  


  




	





  





  








  





  

  

  

  

  

  

</body>
</html>
